{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install simplemma\n",
        "!pip install spacy==3.5.0\n",
        "!pip install es_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zte6-RtoRyZ",
        "outputId": "e278a2f2-0efb-4b4f-b728-53dcc7b54eb3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: simplemma in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement spacy==3.5.0 (from versions: 0.31, 0.32, 0.33, 0.40, 0.51, 0.52, 0.60, 0.61, 0.62, 0.63, 0.64, 0.65, 0.67, 0.68, 0.70, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.90, 0.91, 0.92, 0.93, 0.94, 0.95, 0.97, 0.98, 0.99, 0.100.0, 0.100.1, 0.100.2, 0.100.3, 0.100.4, 0.100.5, 0.100.6, 0.100.7, 0.101.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5, 1.1.0, 1.1.1, 1.1.2, 1.2.0, 1.3.0, 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.7.2, 1.7.3, 1.7.5, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.10.0, 1.10.1, 2.0.0, 2.0.1.dev0, 2.0.1, 2.0.2.dev0, 2.0.2, 2.0.3.dev0, 2.0.3, 2.0.4.dev0, 2.0.4, 2.0.5.dev0, 2.0.5, 2.0.6.dev0, 2.0.6, 2.0.7, 2.0.8, 2.0.9, 2.0.10.dev0, 2.0.10, 2.0.11.dev0, 2.0.11, 2.0.12.dev0, 2.0.12.dev1, 2.0.12, 2.0.13.dev0, 2.0.13.dev1, 2.0.13.dev2, 2.0.13.dev4, 2.0.13, 2.0.14.dev0, 2.0.14.dev1, 2.0.15, 2.0.16.dev0, 2.0.16, 2.0.17.dev0, 2.0.17.dev1, 2.0.17, 2.0.18.dev0, 2.0.18.dev1, 2.0.18, 2.1.0, 2.1.1.dev0, 2.1.1, 2.1.2, 2.1.3, 2.1.4, 2.1.5, 2.1.6, 2.1.7.dev0, 2.1.7, 2.1.8, 2.1.9, 2.2.0.dev10, 2.2.0.dev11, 2.2.0.dev13, 2.2.0.dev15, 2.2.0.dev17, 2.2.0.dev18, 2.2.0.dev19, 2.2.0, 2.2.1, 2.2.2.dev0, 2.2.2.dev3, 2.2.2.dev4, 2.2.2, 2.2.3.dev0, 2.2.3, 2.2.4, 2.3.0.dev1, 2.3.0, 2.3.1, 2.3.2, 2.3.3.dev0, 2.3.3, 2.3.4, 2.3.5, 2.3.6, 2.3.7, 3.0.0, 3.0.1.dev0, 3.0.1, 3.0.2, 3.0.3, 3.0.4, 3.0.5, 3.0.6, 3.0.7, 3.0.8, 3.1.0, 3.1.1, 3.1.2, 3.1.3, 3.1.4, 3.1.5, 3.1.6, 3.2.0, 3.2.1, 3.2.2, 3.2.3, 3.2.4, 3.3.0.dev0, 3.3.0, 3.3.1, 3.4.0, 3.4.1)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for spacy==3.5.0\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: es_core_news_sm in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from es_core_news_sm) (3.1.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.10.0.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.4.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (8.0.17)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (4.64.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.4.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.8.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.10.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.7.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.0.8)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (57.4.0)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (21.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.23.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.9.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->es_core_news_sm) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->es_core_news_sm) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importamos los modulos necesarios\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import SnowballStemmer\n",
        "from operator import itemgetter\n",
        "from nltk import sent_tokenize\n",
        "\n",
        "import simplemma\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe7Zu_WzoVF1",
        "outputId": "f28f38e1-94b2-476b-a5b1-810cb6fe6fff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('elramoazul.txt')\n",
        "string = f.read().replace('\\n',' ').replace('  ',' ')\n",
        "string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Uc1Z2HDvo2Zg",
        "outputId": "e9275f0e-8758-4f39-ceac-b090bceba42c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'El ramo azul, un cuento de Octavio Paz Desperté, cubierto de sudor. Del piso de ladrillos rojos, recién regados, subía un vapor caliente. Una mariposa de alas grisáceas revoloteaba encandilada alrededor del foco amarillento. Salté de la hamaca y descalzo atravesé el cuarto, cuidando no pisar algún alacrán salido de su escondrijo a tomar el fresco. Me acerqué al ventanillo y aspiré el aire del campo. Se oía la respiración de la noche, enorme, femenina. Regresé al centro de la habitación, vacié el agua de la jarra en la palangana de peltre y humedecí la toalla. Me froté el torso y las piernas con el trapo empapado, me sequé un poco y, tras de cerciorarme que ningún bicho estaba escondido entre los pliegues de mi ropa, me vestí y calcé. Bajé saltando la escalera pintada de verde. En la puerta del mesón tropecé con el dueño, sujeto tuerto y reticente. Sentado en una sillita de tule, fumaba con el ojo entrecerrado. Con voz ronca me preguntó: -¿Dónde va señor? -A dar una vuelta. Hace mucho calor. -Hum, todo está ya cerrado. Y no hay alumbrado aquí. Más le valiera quedarse. Alcé los hombros, musité “ahora vuelvo” y me metí en lo oscuro. Al principio no veía nada. Caminé a tientas por la calle empedrada. Encendí un cigarrillo. De pronto salió la luna de una nube negra, iluminando un muro blanco, desmoronado a trechos. Me detuve, ciego ante tanta blancura. Sopló un poco de viento. Respiré el aire de los tamarindos. Vibraba la noche, llena de hojas e insectos. Los grillos vivaqueaban entre las hierbas altas. Alcé la cara: arriba también habían establecido campamento las estrellas. Pensé que el universo era un vasto sistema de señales, una conversación entre seres inmensos. Mis actos, el serrucho del grillo, el parpadeo de la estrella, no eran sino pausas y sílabas, frases dispersas de aquel diálogo. ¿Cuál sería esa palabra de la cual yo era una sílaba? ¿Quién dice esa palabra y a quién se la dice? Tiré el cigarrillo sobre la banqueta. Al caer, describió una curva luminosa, arrojando breves chispas, como un cometa minúsculo. Caminé largo rato, despacio. Me sentía libre, seguro entre los labios que en ese momento me pronunciaban con tanta felicidad. La noche era un jardín de ojos. Al cruzar la calle, sentí que alguien se desprendía de una puerta. Me volví, pero no acerté a distinguir nada. Apreté el paso. Unos instantes percibí unos huaraches sobre las piedras calientes. No quise volverme, aunque sentía que la sombra se acercaba cada vez más. Intenté correr. No pude. Me detuve en seco, bruscamente. Antes de que pudiese defenderme, sentí la punta de un cuchillo en mi espalda y una voz dulce: -No se mueva , señor, o se lo entierro. Sin volver la cara pregunté: -¿Qué quieres? -Sus ojos, señor –contestó la voz suave, casi apenada. -¿Mis ojos? ¿Para qué te servirán mis ojos? Mira, aquí tengo un poco de dinero. No es mucho, pero es algo. Te daré todo lo que tengo, si me dejas. No vayas a matarme. -No tenga miedo, señor. No lo mataré. Nada más voy a sacarle los ojos. -Pero, ¿para qué quieres mis ojos? -Es un capricho de mi novia. Quiere un ramito de ojos azules y por aquí hay pocos que los tengan. Mis ojos no te sirven. No son azules, sino amarillos. -Ay, señor no quiera engañarme. Bien sé que los tiene azules. -No se le sacan a un cristiano los ojos así. Te daré otra cosa. -No se haga el remilgoso, me dijo con dureza. Dé la vuelta. Me volví. Era pequeño y frágil. El sombrero de palma le cubría medio rostro. Sostenía con el brazo derecho un machete de campo, que brillaba con la luz de la luna. -Alúmbrese la cara. Encendí y me acerqué la llama al rostro. El resplandor me hizo entrecerrar los ojos. El apartó mis párpados con mano firme. No podía ver bien. Se alzó sobre las puntas de los pies y me contempló intensamente. La llama me quemaba los dedos. La arrojé. Permaneció un instante silencioso. -¿Ya te convenciste? No los tengo azules. -¡Ah, qué mañoso es usted! –respondió- A ver, encienda otra vez. Froté otro fósforo y lo acerqué a mis ojos. Tirándome de la manga, me ordenó. -Arrodíllese. Mi hinqué. Con una mano me cogió por los cabellos, echándome la cabeza hacia atrás. Se inclinó sobre mí, curioso y tenso, mientras el machete descendía lentamente hasta rozar mis párpados. Cerré los ojos. -Ábralos bien –ordenó. Abrí los ojos. La llamita me quemaba las pestañas. Me soltó de improviso. -Pues no son azules, señor. Dispense. Y despareció. Me acodé junto al muro, con la cabeza entre las manos. Luego me incorporé. A tropezones, cayendo y levantándome, corrí durante una hora por el pueblo desierto. Cuando llegué a la plaza, vi al dueño del mesón, sentado aún frente a la puerta. Entré sin decir palabra. Al día siguiente huí de aquel pueblo. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Tokeniza el texto. ¿Cuántas palabras hay? (sin símbolos de puntuación).\n",
        "\n",
        "# 3. ¿Cuántas palabras diferentes hay?"
      ],
      "metadata": {
        "id": "Uo326LL5rWiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creamos una lista de caracteres especiales\n",
        "caracteres_especiales = ['.','–','¡','!','¿','?',',',':','-',',','“','”','–']"
      ],
      "metadata": {
        "id": "JYzvWFM4pimR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizamos el texto y quitamos los caracteres especiales\n",
        "tokens = nltk.word_tokenize(string)\n",
        "a_ = []\n",
        "for token in tokens:\n",
        "    if token in caracteres_especiales:\n",
        "        tokens.remove(token)\n",
        "\n",
        "\n",
        "for j in caracteres_especiales:\n",
        "    for indice, palabra in enumerate(tokens):\n",
        "        x = palabra.replace(j,'')\n",
        "        tokens[indice] = x\n",
        "    \n",
        "\n",
        "print('El número de palabras si quitar duplicados es {}'.format(len(tokens)))\n",
        "print('El número de palabras sin duplicados es {}'.format(len(set(tokens))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAv-6vnynkKU",
        "outputId": "5afa59cd-08a2-471a-f2ea-4392d6461db6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El número de palabras si quitar duplicados es 826\n",
            "El número de palabras sin duplicados es 466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Para cada palabra, da el lema y la raíz."
      ],
      "metadata": {
        "id": "U0Qb-igStHG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palabras_distintas = list(set(tokens))\n",
        "\n",
        "for indice,palabra in enumerate(palabras_distintas):\n",
        "    palabras_distintas[indice] = palabra.lower()"
      ],
      "metadata": {
        "id": "HxZqGc0jtGgk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lema\n",
        "spanish_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lema =[]\n",
        "for word in palabras_distintas:\n",
        "  lema.append(simplemma.lemmatize(word, lang='es'))\n",
        "lema"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBggjDoezPau",
        "outputId": "64099f53-4506-40b4-b88f-78a4ec90f9f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['lentamente',\n",
              " 'detener',\n",
              " 'tamarindo',\n",
              " 'algo',\n",
              " 'dedo',\n",
              " 'ninguno',\n",
              " 'ver',\n",
              " 'tropezón',\n",
              " 'dar',\n",
              " 'frotar',\n",
              " 'nada',\n",
              " 'aspirar',\n",
              " 'cerrar',\n",
              " 'palabra',\n",
              " 'alumbrado',\n",
              " 'cubierto',\n",
              " 'cerciorarme',\n",
              " 'él',\n",
              " 'por',\n",
              " 'atrás',\n",
              " 'machete',\n",
              " 'mucho',\n",
              " 'señalar',\n",
              " 'cuidar',\n",
              " 'estar',\n",
              " 'tener',\n",
              " 'llamita',\n",
              " 'hamaca',\n",
              " 'preguntar',\n",
              " 'ante',\n",
              " 'convencer',\n",
              " 'mientras',\n",
              " 'subir',\n",
              " 'bien',\n",
              " 'derecho',\n",
              " 'hacer',\n",
              " 'sílaba',\n",
              " 'labio',\n",
              " 'vasto',\n",
              " 'volver',\n",
              " 'atravesar',\n",
              " 'usted',\n",
              " 'caminar',\n",
              " 'sílaba',\n",
              " 'siguiente',\n",
              " 'ya',\n",
              " 'revolotear',\n",
              " 'como',\n",
              " 'volver',\n",
              " 'su',\n",
              " 'alzar',\n",
              " 'meter',\n",
              " 'femenino',\n",
              " 'alguien',\n",
              " 'brazo',\n",
              " 'dónde',\n",
              " 'cabello',\n",
              " 'quedarse',\n",
              " 'mira',\n",
              " 'felicidad',\n",
              " 'ser',\n",
              " 'curioso',\n",
              " 'sombrero',\n",
              " 'acertar',\n",
              " 'junto',\n",
              " 'tenso',\n",
              " 'yo',\n",
              " 'mano',\n",
              " 'alguno',\n",
              " 'hacer',\n",
              " 'ver',\n",
              " 'rato',\n",
              " 'frágil',\n",
              " 'ventanillo',\n",
              " 'ser',\n",
              " 'durante',\n",
              " 'pequeño',\n",
              " 'servir',\n",
              " 'alta',\n",
              " 'alumbrarse',\n",
              " 'sentar',\n",
              " 'tomar',\n",
              " 'arrojar',\n",
              " 'arribar',\n",
              " 'ojo',\n",
              " 'vivaquear',\n",
              " 'instante',\n",
              " 'coger',\n",
              " 'salir',\n",
              " 'empapar',\n",
              " 'firme',\n",
              " 'verde',\n",
              " 'descalzo',\n",
              " 'él',\n",
              " 'si',\n",
              " 'poco',\n",
              " 'querer',\n",
              " 'tener',\n",
              " 'nada',\n",
              " 'noviar',\n",
              " 'jarra',\n",
              " 'con',\n",
              " 'habitación',\n",
              " 'con',\n",
              " 'volver',\n",
              " 'y',\n",
              " 'ser',\n",
              " 'respiración',\n",
              " 'percibir',\n",
              " 'fósforo',\n",
              " 'sostener',\n",
              " 'cerrar',\n",
              " 'saltar',\n",
              " 'cruzar',\n",
              " 'jardín',\n",
              " 'correr',\n",
              " 'poder',\n",
              " 'sino',\n",
              " 'de',\n",
              " 'ser',\n",
              " 'sombra',\n",
              " 'acercar',\n",
              " 'mi',\n",
              " 'palangana',\n",
              " 'llegar',\n",
              " 'del',\n",
              " 'no',\n",
              " 'permanecer',\n",
              " 'aquí',\n",
              " 'levantándome',\n",
              " 'oscuro',\n",
              " 'vaciar',\n",
              " 'empedrar',\n",
              " 'pronunciar',\n",
              " 'mañoso',\n",
              " 'deja',\n",
              " 'hasta',\n",
              " 'correr',\n",
              " 'intentar',\n",
              " 'querer',\n",
              " 'mi',\n",
              " 'aún',\n",
              " 'paso',\n",
              " 'insecto',\n",
              " 'saltar',\n",
              " 'cigarrillo',\n",
              " 'paz',\n",
              " 'tener',\n",
              " 'huir',\n",
              " 'en',\n",
              " 'y',\n",
              " 'alzar',\n",
              " 'entre',\n",
              " 'vapor',\n",
              " 'día',\n",
              " 'luz',\n",
              " 'acto',\n",
              " 'párpado',\n",
              " 'respirar',\n",
              " 'inmenso',\n",
              " 'tirar',\n",
              " 'salir',\n",
              " 'cosa',\n",
              " 'ciego',\n",
              " 'hora',\n",
              " 'soplar',\n",
              " 'hoja',\n",
              " 'dispersar',\n",
              " 'ese',\n",
              " 'hierba',\n",
              " 'luego',\n",
              " 'e',\n",
              " 'grisáceo',\n",
              " 'mano',\n",
              " 'servir',\n",
              " 'instante',\n",
              " 'encender',\n",
              " 'cada',\n",
              " 'cuento',\n",
              " 'frase',\n",
              " 'piedra',\n",
              " 'azul',\n",
              " 'uno',\n",
              " 'cual',\n",
              " 'tú',\n",
              " 'valer',\n",
              " 'bajar',\n",
              " 'pisar',\n",
              " 'hincar',\n",
              " 'tuerto',\n",
              " 'tener',\n",
              " 'entierro',\n",
              " 'escalera',\n",
              " 'poder',\n",
              " 'despacio',\n",
              " 'desmoronar',\n",
              " 'sentir',\n",
              " 'luna',\n",
              " 'intensamente',\n",
              " 'el',\n",
              " 'arrojar',\n",
              " 'haber',\n",
              " 'poco',\n",
              " 'vez',\n",
              " 'brillar',\n",
              " 'mesón',\n",
              " 'yo',\n",
              " 'quién',\n",
              " 'fresco',\n",
              " 'caliente',\n",
              " 'para',\n",
              " 'inclinar',\n",
              " 'ser',\n",
              " 'ser',\n",
              " 'pensar',\n",
              " 'pausa',\n",
              " 'caliente',\n",
              " 'octavio',\n",
              " 'mariposa',\n",
              " 'uno',\n",
              " 'dinero',\n",
              " 'despertar',\n",
              " 'parpadeo',\n",
              " 'aquel',\n",
              " 'el',\n",
              " 'tienta',\n",
              " 'aire',\n",
              " 'enorme',\n",
              " 'caer',\n",
              " 'establecer',\n",
              " 'cuál',\n",
              " 'uno',\n",
              " 'vaya',\n",
              " 'en',\n",
              " 'ver',\n",
              " 'improviso',\n",
              " 'diálogo',\n",
              " 'bruscamente',\n",
              " 'querer',\n",
              " 'humedecer',\n",
              " 'suave',\n",
              " 'ramo',\n",
              " 'cuando',\n",
              " 'capricho',\n",
              " 'muro',\n",
              " 'libre',\n",
              " 'son',\n",
              " 'rojo',\n",
              " 'foco',\n",
              " 'principio',\n",
              " 'soltar',\n",
              " 'ramito',\n",
              " 'así',\n",
              " 'amarillo',\n",
              " 'ay',\n",
              " 'acercar',\n",
              " 'grillo',\n",
              " 'rostro',\n",
              " 'echándome',\n",
              " 'su',\n",
              " 'qué',\n",
              " 'mover',\n",
              " 'agua',\n",
              " 'mi',\n",
              " 'el',\n",
              " 'ah',\n",
              " 'sin',\n",
              " 'poder',\n",
              " 'cristiano',\n",
              " 'centro',\n",
              " 'sobre',\n",
              " 'ropa',\n",
              " 'arrodillarse',\n",
              " 'noche',\n",
              " 'incorporar',\n",
              " 'fumar',\n",
              " 'espalda',\n",
              " 'tropezar',\n",
              " 'querer',\n",
              " 'no',\n",
              " 'sillita',\n",
              " 'señor',\n",
              " 'cabeza',\n",
              " 'secar',\n",
              " 'bicho',\n",
              " 'para',\n",
              " 'vestir',\n",
              " 'entrar',\n",
              " 'otro',\n",
              " 'alacrán',\n",
              " 'oír',\n",
              " 'todo',\n",
              " 'sistema',\n",
              " 'estrella',\n",
              " 'escondrijo',\n",
              " 'quién',\n",
              " 'desparecer',\n",
              " 'ir',\n",
              " 'frente',\n",
              " 'azular',\n",
              " 'apenar',\n",
              " 'pestaña',\n",
              " 'apartar',\n",
              " 'defenderme',\n",
              " 'engañarme',\n",
              " 'miedo',\n",
              " 'dar',\n",
              " 'peltre',\n",
              " 'pero',\n",
              " 'cara',\n",
              " 'cubrir',\n",
              " 'pronto',\n",
              " 'a',\n",
              " 'sacar',\n",
              " 'pero',\n",
              " 'pueblo',\n",
              " 'ahora',\n",
              " 'campamento',\n",
              " 'minúsculo',\n",
              " 'trecho',\n",
              " 'tirándome',\n",
              " 'huaraches',\n",
              " 'seco',\n",
              " 'también',\n",
              " 'vibrar',\n",
              " 'el',\n",
              " 'banqueta',\n",
              " 'remilgoso',\n",
              " 'punta',\n",
              " 'entrecerrar',\n",
              " 'hum',\n",
              " 'tras',\n",
              " 'antes',\n",
              " 'campo',\n",
              " 'matarme',\n",
              " 'grillo',\n",
              " 'uno',\n",
              " 'bien',\n",
              " 'serrucho',\n",
              " 'ser',\n",
              " 'el',\n",
              " 'regar',\n",
              " 'rozar',\n",
              " 'o',\n",
              " 'largo',\n",
              " 'pierna',\n",
              " 'más',\n",
              " 'contestar',\n",
              " 'el',\n",
              " 'ordenar',\n",
              " 'entrecerrar',\n",
              " 'matar',\n",
              " 'distinguir',\n",
              " 'a',\n",
              " 'encender',\n",
              " 'ese',\n",
              " 'voz',\n",
              " 'decir',\n",
              " 'toalla',\n",
              " 'blancura',\n",
              " 'silencioso',\n",
              " 'sin',\n",
              " 'ser',\n",
              " 'mí',\n",
              " 'conversación',\n",
              " 'describir',\n",
              " 'estar',\n",
              " 'el',\n",
              " 'seguro',\n",
              " 'sujeto',\n",
              " 'apretar',\n",
              " 'llena',\n",
              " 'blanco',\n",
              " 'ronca',\n",
              " 'breve',\n",
              " 'tanto',\n",
              " 'decir',\n",
              " 'llama',\n",
              " 'alrededor',\n",
              " 'dar',\n",
              " 'pintada',\n",
              " 'recién',\n",
              " 'hacer',\n",
              " 'ir',\n",
              " 'dispensar',\n",
              " 'resplandor',\n",
              " 'puerta',\n",
              " 'haber',\n",
              " 'de',\n",
              " 'manga',\n",
              " 'responder',\n",
              " 'dueño',\n",
              " 'medio',\n",
              " 'luminoso',\n",
              " 'calcar',\n",
              " 'ya',\n",
              " 'del',\n",
              " 'desierto',\n",
              " 'preguntar',\n",
              " 'volverme',\n",
              " 'más',\n",
              " 'aunque',\n",
              " 'ladrillo',\n",
              " 'palma',\n",
              " 'frotar',\n",
              " 'cuchillo',\n",
              " 'pliegue',\n",
              " 'negro',\n",
              " 'sentir',\n",
              " 'acodar',\n",
              " 'viento',\n",
              " 'que',\n",
              " 'momento',\n",
              " 'iluminar',\n",
              " 'quemar',\n",
              " 'estrella',\n",
              " 'al',\n",
              " 'desprender',\n",
              " 'dureza',\n",
              " 'otro',\n",
              " 'caer',\n",
              " 'punta',\n",
              " 'dulce',\n",
              " 'universo',\n",
              " 'musitar',\n",
              " 'regresar',\n",
              " 'pie',\n",
              " 'abrir',\n",
              " 'sacarle',\n",
              " 'curva',\n",
              " 'sentar',\n",
              " 'vuelta',\n",
              " 'cometa',\n",
              " 'hacia',\n",
              " 'sudor',\n",
              " 'torso',\n",
              " 'trapo',\n",
              " 'calle',\n",
              " 'al',\n",
              " 'tú',\n",
              " 'nube',\n",
              " 'qué',\n",
              " 'uno',\n",
              " 'esconder',\n",
              " 'cuarto',\n",
              " 'yo',\n",
              " 'decir',\n",
              " 'descender',\n",
              " 'contemplar',\n",
              " 'encandilar',\n",
              " 'piso',\n",
              " 'calor',\n",
              " 'mi',\n",
              " 'ala',\n",
              " 'reticente',\n",
              " 'tule',\n",
              " 'hombro',\n",
              " 'casi',\n",
              " 'plaza',\n",
              " 'chispa',\n",
              " 'pues',\n",
              " 'amarillento',\n",
              " 'ojo',\n",
              " 'él',\n",
              " 'ábralos',\n",
              " 'él']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stems\n",
        "spanish_stemmer = SnowballStemmer(language='spanish')\n",
        "\n",
        "stems = []\n",
        "for palabra in palabras_distintas:\n",
        "    stems.append(spanish_stemmer.stem(palabra))"
      ],
      "metadata": {
        "id": "q21Ia7NowHY7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Después de lematizar las palabras, ¿cuántas palabras diferentes hay?"
      ],
      "metadata": {
        "id": "uj9AjXSVtKp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('La cantidad de palabras distintas despues de lematizar son: {}'.format(len(set(lema))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olsYjmIhpatr",
        "outputId": "737885e9-d783-43ae-e2ab-8c06dbd2207c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La cantidad de palabras distintas despues de lematizar son: 375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. ¿Cuál es la diversidad léxica del texto dado? (relación de palabras únicas con respecto al número total de palabras)"
      ],
      "metadata": {
        "id": "2-pVQhiztWki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(tokens))/len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ez6HsJcutW1K",
        "outputId": "fcd72b54-e02b-4411-8e5e-223dcc323e9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5641646489104116"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. ¿Cuáles son las 20 palabras léxicas más frecuentes en el texto? ¿Cuál es su frecuencia?"
      ],
      "metadata": {
        "id": "CZ9OG54Vtb-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens2  = []\n",
        "for j in tokens:\n",
        "    tokens2.append(j.lower())\n",
        "\n",
        "frecuencias = {}\n",
        "for j in tokens2:\n",
        "    frecuencias[j] = 0\n",
        "\n",
        "for j in tokens2:\n",
        "    frecuencias[j] += 1\n",
        "\n",
        "frecuentes = []\n",
        "for llave,valor in frecuencias.items():\n",
        "    frecuentes.append([llave,valor])"
      ],
      "metadata": {
        "id": "EfRbTQlx27hL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_fre = sorted(frecuentes, key=itemgetter(1),reverse=True)\n",
        "print(top_fre[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ds_GuqMG4WRd",
        "outputId": "e82ad22c-d4ce-4605-c8c2-7cd5b8a6e7e2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['de', 37], ['la', 36], ['me', 24], ['el', 22], ['y', 20], ['no', 20], ['un', 16], ['los', 16], ['a', 14], ['ojos', 13], ['una', 11], ['con', 11], ['se', 10], ['que', 10], ['al', 9], ['mis', 8], ['en', 7], ['las', 7], ['del', 6], ['señor', 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. ¿Cuál es el número promedio de palabras por oración?"
      ],
      "metadata": {
        "id": "Fszq3Q0Utg1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oraciones = sent_tokenize(string)\n",
        "for j in caracteres_especiales:\n",
        "    for indice, palabra in enumerate(oraciones):\n",
        "        x = palabra.replace(j,'')\n",
        "        oraciones[indice] = x\n",
        "\n",
        "palabra_por_oraciones = [j.split() for j in oraciones]\n",
        "\n",
        "num_palabras = []\n",
        "for lista in palabra_por_oraciones:\n",
        "    num_palabras.append(len(lista))\n",
        "\n",
        "print('El promedio de palabras por oración es: {}'.format(np.array(num_palabras).mean()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvHFKUSytgrs",
        "outputId": "9fabf89c-e380-4b66-a81f-6c3efc0c0298"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El promedio de palabras por oración es: 7.866666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. ¿Cuál  es la frecuencia de de sustantivos, adjetivos y verbos en el texto?."
      ],
      "metadata": {
        "id": "1LIrpoj3tlHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import es_core_news_sm\n",
        "nlp = es_core_news_sm.load()"
      ],
      "metadata": {
        "id": "GmAfCiratk7Q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for j in caracteres_especiales:\n",
        "    string = string.replace(j,'')\n",
        "\n",
        "doc = nlp(string)\n",
        "b_ = [(w.text, w.pos_) for w in doc]\n",
        "\n",
        "adj = 0\n",
        "noun = 0\n",
        "verb = 0\n",
        "for j in b_:\n",
        "    if j[1] == 'NOUN':\n",
        "        noun += 1\n",
        "    elif j[1] == 'ADJ':\n",
        "        adj += 1\n",
        "    elif j[1] == 'VERB':\n",
        "        verb += 1\n",
        "\n",
        "print('La cantidad de adjetivos que hay es {}'.format(adj))\n",
        "print('La cantidad de sustantivos que hay es {}'.format(noun))\n",
        "print('La cantidad de verbos que hay es {}'.format(verb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykGiSZIV_RHg",
        "outputId": "539247d3-af23-4052-d391-80f9a0d00b1a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La cantidad de adjetivos que hay es 66\n",
            "La cantidad de sustantivos que hay es 173\n",
            "La cantidad de verbos que hay es 121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t9TNQpVv_9SX"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}